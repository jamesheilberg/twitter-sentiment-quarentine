{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import *\n",
    "from tweepy.auth import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from textblob import TextBlob\n",
    "\n",
    "from googlemaps import *\n",
    "\n",
    "import re\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting up the API authentication.\n",
    "\n",
    "\n",
    "class Authenticator():\n",
    "    # This class will handle authentication for the twitter API.\n",
    "    \n",
    "    def auth(self):\n",
    "        auth = OAuthHandler(twitter_auth.consumer_key, twitter_auth.consumer_secret)\n",
    "        auth.set_access_token(twitter_auth.access_token, twitter_auth.access_token_secret)\n",
    "        return auth\n",
    "    \n",
    "class MyT():\n",
    "    def __init__(self, user=None):\n",
    "        # Iniatiate the user, auth, and my_t or my twitter is the API pointer\n",
    "        \n",
    "        self.user = user\n",
    "        self.auth = Authenticator().auth()\n",
    "        self.my_t = API(self.auth)\n",
    "\n",
    "    def user_timeline_head(self, n):\n",
    "        # Like pandas, returns n tweets from the top of the users home timeline\n",
    "        \n",
    "        tweets = []\n",
    "        for tweet in Cursor(self.my_t.user_timeline, id=self.user).items(n):\n",
    "            tweets.append(tweet)\n",
    "        return tweets\n",
    "\n",
    "    def get_my_friends(self, n):\n",
    "        # Get n number of friends of myt.\n",
    "        \n",
    "        friend_list = []\n",
    "        for friend in Cursor(self.my_t.friends, id=self.user).items(n):\n",
    "            friend_list.append(friend)\n",
    "        return friend_list\n",
    "\n",
    "    def home_timeline_head(self, n):\n",
    "        # Like pandas, returns n tweets from the top of the users home timeline\n",
    "        \n",
    "        timeline = []\n",
    "        for tweet in Cursor(self.my_t.home_timeline, id=self.user).items(n):\n",
    "            timeline.append(tweet)\n",
    "        return timeline\n",
    "    \n",
    "    def get_my_t_api(self):\n",
    "        # Gets the twiter api pointer\n",
    "        \n",
    "        return self.my_t\n",
    "\n",
    "class TwitterStreamer():\n",
    "    \n",
    "    def stream_tweets(self, fetched_tweets_filename, search_hashtags):\n",
    "        # A function that will stream and process tweets given hashtag parameter\n",
    "        \n",
    "        listener = StdOutListener(fetched_tweets_filename)\n",
    "        auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        \n",
    "        stream = Stream(auth, listener)\n",
    "        \n",
    "        stream.filter(track=search_hashtags)\n",
    "\n",
    "class StdOutListener(StreamListener):\n",
    "    # Basic listener class that will handle good data and errors\n",
    "    \n",
    "    def __init__(self, fetched_tweets_filename):\n",
    "        self.fetched_tweets_filename = fetched_tweets_filename\n",
    "    \n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            print(data)\n",
    "            with open(self.fetched_tweets_filename, 'a') as tf:\n",
    "                tf.write(data)\n",
    "            return True\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "        return True\n",
    "    \n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "        \n",
    "if __name__ == \"__main__\": \n",
    "    \n",
    "    hash_tag_list = ['donald trump']\n",
    "    fetched_tweets_filename = 'tweets.json'\n",
    "    my_twitter = MyT('POTUS')\n",
    "    print(my_twitter.user_timeline_head(5).filter(track=hash_tag_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetAnalyzer():\n",
    "    # This class will contain basic tweet analyzation tools \n",
    "    def arrTweetToDf(self, tweets):\n",
    "        # covert tweet to a dataFrame so we can take full advantage of pandas and the numpy liberaries\n",
    "        # neat\n",
    "        \n",
    "        df = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
    "\n",
    "        df['id'] = np.array([tweet.id for tweet in tweets])\n",
    "        df['len'] = np.array([len(tweet.text) for tweet in tweets])\n",
    "        df['date'] = np.array([tweet.created_at for tweet in tweets])\n",
    "        df['source'] = np.array([tweet.source for tweet in tweets])\n",
    "        df['likes'] = np.array([tweet.favorite_count for tweet in tweets])\n",
    "        df['retweets'] = np.array([tweet.retweet_count for tweet in tweets])\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myt = MyT()\n",
    "tanal = TweetAnalyzer()\n",
    "api = myt.get_my_t_api()\n",
    "\n",
    "tweets = api.home_timeline(20)\n",
    "\n",
    "df = tanal.arrTweetToDf(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps, collect \n",
    "#\n",
    "#\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 5\n",
    "last_day = datetime.now()\n",
    "start_date = last_day - timedelta(days = lookback)\n",
    "end_date = last_day\n",
    "day = timedelta(days = 1)\n",
    "search_words = \"quarentine -filter:retweets\"\n",
    "\n",
    "\n",
    "tweets = tweepy.Cursor(api.search,\n",
    "                  q=search_words,\n",
    "                  lang=\"en\",\n",
    "                  since=str(start_date)[:10],\n",
    "                  until=str(start_date + day + day)[:10]).items(3)\n",
    "\n",
    "users_locs = [[\n",
    "        tweet.user.screen_name,\n",
    "        tweet.user.location,\n",
    "        tweet.created_at,\n",
    "        tweet.favorite_count] for tweet in tweets]\n",
    "\n",
    "df = pd.DataFrame(data=users_locs, columns=['user', \"location\", \"created\", \"likes\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = \"#quarentine -filter:retweets\"\n",
    "\n",
    "#tweets per day in range\n",
    "resolution = 50\n",
    "\n",
    "# Collect tweets\n",
    "def get_tweet_df(date_since, date_until):\n",
    "    tweets = tweepy.Cursor(api.search,\n",
    "                  q=search_words,\n",
    "                  lang=\"en\",\n",
    "                  since=date_since,\n",
    "                  until=date_until).items(300)\n",
    "\n",
    "    users_locs = [[\n",
    "        tweet.user.screen_name,\n",
    "        tweet.user.location,\n",
    "        tweet.created_at,\n",
    "        tweet.favorite_count] for tweet in tweets]\n",
    "\n",
    "    df = pd.DataFrame(data=users_locs, columns=['user', \"location\", \"created\", \"likes\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_tweet_range_df(lookback = 90, last_day = datetime.now(), resolution = 1):\n",
    "    # lookback = days to look back from\n",
    "    # last day = end of looking period, set to today\n",
    "    # resultion = tweets per day that will come up\n",
    "    \n",
    "    start_date = last_day - timedelta(days = lookback)\n",
    "    end_date = last_day\n",
    "    day = timedelta(days = 1)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    days = 0\n",
    "    \n",
    "    while start_date < end_date:\n",
    "        days += 1\n",
    "        \n",
    "        #print(str(start_date)[:10])\n",
    "        tweets = tweepy.Cursor(api.search,\n",
    "                      q=search_words,\n",
    "                      lang=\"en\",\n",
    "                      since=str(start_date)[:10],\n",
    "                      until=str(start_date + day)[:10]).items(resolution)\n",
    "\n",
    "        start_date += day\n",
    "        \n",
    "        users_locs = [[\n",
    "            tweet.text,\n",
    "            tweet.user.screen_name,\n",
    "            tweet.user.location,\n",
    "            tweet.created_at,\n",
    "            tweet.favorite_count] for tweet in tweets]\n",
    "\n",
    "        dfAppend = pd.DataFrame(data=users_locs, columns=['tweet', 'user', \"location\", \"created\", \"likes\"])\n",
    "\n",
    "        #print(dfAppend)\n",
    "        \n",
    "        df = df.append(dfAppend, ignore_index=True)\n",
    "        \n",
    "    #print(days)\n",
    "    return df\n",
    "\n",
    "df = get_tweet_range_df(lookback = 10, resolution = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gmaps = Client(key='AIzaSyCdBA39xq1V7E7olkINdWijGe7bRX9UZkg')\n",
    "geo = gmaps.geocode('Central Canada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.657 -95.989\n"
     ]
    }
   ],
   "source": [
    "lats = []\n",
    "lons = []\n",
    "\n",
    "count = 0\n",
    "for item in geo[0]['geometry']['bounds']:\n",
    "    for latlon in geo[0]['geometry']['bounds'][item]:\n",
    "        if count%2 == 0:\n",
    "            lats.append(geo[0]['geometry']['bounds'][item][latlon])\n",
    "        else:\n",
    "            lons.append(geo[0]['geometry']['bounds'][item][latlon])\n",
    "        count += 1\n",
    "        \n",
    "lat = sum(lats)/len(lats)\n",
    "lon = sum(lons)/len(lons)\n",
    "\n",
    "return [round(lat, 3), round(lon, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterSentimentAnalysis():\n",
    "    # This class will handle everything that is part getting a sentiment analysis\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        consumer_key = \"3LntKM9D0jXZbKhE9G0ek63Ar\"\n",
    "        consumer_secret = \"QNXlkRAUrCRiiEZacnSEnRW4Oeze3h5romq0YG48IPsb62BuoA\"\n",
    "\n",
    "        access_token = \"1252051453474111491-MLxtYXJAicSFnWI0pfJiFxOd6OhICJ\"\n",
    "        access_token_secret = \"nMjIIjMyqsMxnRUlpiOGCGOPsWCuRgByNTH3E5LS1AAS0\"\n",
    "        \n",
    "        self.search_words = \"#quarentine -filter:retweets\"\n",
    "        self.today = datetime.now()\n",
    "        \n",
    "        try:\n",
    "            # handle authentication and possible issues\n",
    "            \n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "            self.auth.set_access_token(access_token, access_token_secret)\n",
    "            self.api = API(self.auth, wait_on_rate_limit=True)\n",
    "            \n",
    "        except:\n",
    "            print(\"Twitter Authentication Failed! Check API\")\n",
    "            raise Exception()\n",
    "            \n",
    "        try:\n",
    "            self.gmaps = Client(key='AIzaSyCdBA39xq1V7E7olkINdWijGe7bRX9UZkg')\n",
    "        except:\n",
    "            \n",
    "            print(\"GMAPS Authentication Failed! Check API\")\n",
    "            raise Exception()\n",
    "    \n",
    "    def parse_tweet(self, tweet):\n",
    "        # A regular expression, to clean tweets\n",
    "        # This will ultimatly remove links or any special character that may interfere with NLP\n",
    "        ### REMEMBER: we want a sentiment of the text, not anything linked to it\n",
    "        \n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "    \n",
    "\n",
    "    def tweet_sentiment_score(self, tweet):\n",
    "        # This will score the tweets sentiment based on textblob's sentiment method\n",
    "        # more information can be found out about textblob in the documentation\n",
    "        # link here: https://textblob.readthedocs.io/en/dev/index.html\n",
    "        \n",
    "        # TextBlob object <-- a\n",
    "        a = TextBlob(self.parse_tweet(tweet))\n",
    "        \n",
    "        '''\n",
    "        #for debugging\n",
    "        \n",
    "        if a.sentiment.polarity > 0:\n",
    "            print('positive')\n",
    "        elif a.sentiment.polarity == 0:\n",
    "            print('neutral')\n",
    "        else:\n",
    "            print('negative')\n",
    "        '''\n",
    "            \n",
    "        return a.sentiment.polarity\n",
    "    \n",
    "    def get_df_sentiments(self, dataframe):\n",
    "\n",
    "        df = dataframe.copy()\n",
    "\n",
    "        try:        \n",
    "            df['sentiment'] = [self.tweet_sentiment_score(tweet) for tweet in df['tweet']]\n",
    "        except:\n",
    "            print(\"error collection sentiment (is dataframe intitialized?)\")\n",
    "            raise Exception()\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def get_tweet_range_df(self, lookback, tweets_per_day, senti=True, cleanloc=True, getCentroid=True):\n",
    "        # lookback = days to look back from\n",
    "        # last day = end of looking period, set to today\n",
    "        # resultion = tweets per day that will come up\n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "        ed = self.today\n",
    "        sd = self.today - timedelta(days=lookback)\n",
    "        day = timedelta(days = 1)\n",
    "\n",
    "        days = 0\n",
    "        \n",
    "        # This will get us a 'random' sample of tweets each day from all across the globe\n",
    "        # CONSTRAINT: MUST BE ENGLISH AND HAVING TO DO WITH QUARENTINE\n",
    "        while sd < ed:\n",
    "            days += 1\n",
    "    \n",
    "            #print(str(start_date)[:10])\n",
    "            tweets = tweepy.Cursor(self.api.search,\n",
    "                          q=self.search_words,\n",
    "                          lang=\"en\",\n",
    "                          since=str(sd)[:10],\n",
    "                          until=str(sd + day)[:10]).items(tweets_per_day)\n",
    "\n",
    "            sd += day\n",
    "\n",
    "            users_locs = [[\n",
    "                tweet.text,\n",
    "                tweet.user.screen_name,\n",
    "                tweet.user.location,\n",
    "                tweet.created_at,\n",
    "                tweet.favorite_count] for tweet in tweets]\n",
    "\n",
    "            dfAppend = pd.DataFrame(data=users_locs, columns=['tweet', 'user', \"location\", \"created\", \"likes\"])\n",
    "\n",
    "            #print(dfAppend)\n",
    "\n",
    "            df = df.append(dfAppend, ignore_index=True)\n",
    "        #print(days)\n",
    "        \n",
    "        if senti:\n",
    "            # add sentiment to our dataframe\n",
    "            \n",
    "            df = self.get_df_sentiments(df)\n",
    "            \n",
    "        #country_list = []\n",
    "        lats = []\n",
    "        lons = []\n",
    "            \n",
    "        if cleanloc:\n",
    "            # This condition will get a lat/lon pair for the location proiveded if google maps can process it\n",
    "            # if not it will remain Nan\n",
    "            c = 0\n",
    "            #coordSet = False\n",
    "            for loc in df['location']:\n",
    "                #coordSet = False\n",
    "                c += 1\n",
    "                #print(\"itter\")\n",
    "                    #we can use the tweet parser to also parse the addresses\n",
    "                 #   print(loc)\n",
    "\n",
    "                if loc == '': \n",
    "                    #country_list.append(np.nan)\n",
    "                    lats.append(np.nan)\n",
    "                    #print(\"adding nan to lat, itter: \" + str(c))\n",
    "                    lons.append(np.nan)\n",
    "                    continue\n",
    "                    \n",
    "                gmapsRETURN = self.gmaps.geocode(loc)\n",
    "\n",
    "                la = []\n",
    "                lo = []\n",
    "\n",
    "                count = 0\n",
    "\n",
    "                try:\n",
    "                    #x = gmapsRETURN[0]['address_components']\n",
    "                    y = gmapsRETURN[0]['geometry']['bounds']\n",
    "                    \n",
    "                except:\n",
    "                    #print(\"adding nan to lat, itter: \" + str(c))\n",
    "                    lats.append(np.nan)\n",
    "                    lons.append(np.nan)\n",
    "                    #country_list.append(np.nan)\n",
    "                    #print('nanE')\n",
    "                    continue\n",
    "                \n",
    "                '''   \n",
    "                for item in gmapsRETURN[0]['address_components']:\n",
    "                    if item['types'] == ['country', 'political']:\n",
    "                        print(item['long_name'])\n",
    "                        country_list.append(item['long_name'])\n",
    "                '''\n",
    "                for item in gmapsRETURN[0]['geometry']['bounds']:\n",
    "                    for latlon in gmapsRETURN[0]['geometry']['bounds'][item]:\n",
    "                        if count%2 == 0:\n",
    "                            la.append(gmapsRETURN[0]['geometry']['bounds'][item][latlon])\n",
    "                        else:\n",
    "                            lo.append(gmapsRETURN[0]['geometry']['bounds'][item][latlon])\n",
    "                        count += 1\n",
    "\n",
    "                la = round(sum(la)/len(la), 3)\n",
    "                lo = round(sum(lo)/len(lo), 3)\n",
    "\n",
    "                #print(\"adding \"+ str(la) +\" to lat, itter: \" + str(c))\n",
    "                lats.append(la)\n",
    "                lons.append(lo)\n",
    "                continue\n",
    "\n",
    "        #print(len(df))\n",
    "        #print(len(lats), len(lons))\n",
    "        #df['country'] = country_list\n",
    "        df['centroid_lats'] = lats\n",
    "        df['centroid_lons'] = lons\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def update(self, df, filepath='csvFiles/tweets.csv'):\n",
    "        return df.to_csv(filepath, index=False)\n",
    "    \n",
    "    def read_csv(self, fname='csvFiles/tweets.csv'):\n",
    "        df = pd.read_csv(fname)\n",
    "        df['created'] = pd.to_datetime(df['created'])\n",
    "        return df\n",
    "    \n",
    "    def get_by_date(self, df, lookback):\n",
    "        firstd = self.today - timedelta(days=lookback)\n",
    "        df = df[(df['created']>firstd) & (df['created']<self.today)]\n",
    "        df = df.resample('D', on='created').mean()\n",
    "        del df['likes']\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def get_by_country(self, df):\n",
    "        df = df[df['country'].notna()]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df = df.groupby('country').agg({'sentiment':'mean'}).reset_index()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def gets_dates_as_list(self, df):\n",
    "        return [str(item)[:10] for item in df.index.to_series()]\n",
    "    \n",
    "    def get_lat_lons_and_senti(self, df, lookback):\n",
    "        df = df[['sentiment', 'centroid_lats', 'centroid_lons', 'created']]\n",
    "        df = df[df['centroid_lats'].notna()]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df['heatmap_weight'] = [(2.5*senti+2.5) for senti in df['sentiment']]\n",
    "        \n",
    "        firstd = self.today - timedelta(days=lookback)\n",
    "        df = df[(df['created']>firstd) & (df['created']<self.today)]\n",
    "        df = df[['sentiment', 'centroid_lats', 'centroid_lons', 'created']]\n",
    "        return df\n",
    "\n",
    "    def gets_sentiment_as_list(self, df):\n",
    "        return [item for item in df['sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TwitterSentimentAnalysis()\n",
    "df = a.get_tweet_range_df(7, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>centroid_lats</th>\n",
       "      <th>centroid_lons</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>0.078929</td>\n",
       "      <td>14.03100</td>\n",
       "      <td>1.646667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>-0.097576</td>\n",
       "      <td>-14.40900</td>\n",
       "      <td>-51.317000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>29.72050</td>\n",
       "      <td>-51.479500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-30</td>\n",
       "      <td>0.293636</td>\n",
       "      <td>33.55025</td>\n",
       "      <td>-94.267250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>0.105500</td>\n",
       "      <td>-5.46250</td>\n",
       "      <td>-112.516500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>0.183571</td>\n",
       "      <td>26.64000</td>\n",
       "      <td>-89.185250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>9.87950</td>\n",
       "      <td>-81.623500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sentiment  centroid_lats  centroid_lons\n",
       "created                                            \n",
       "2020-05-27   0.078929       14.03100       1.646667\n",
       "2020-05-28  -0.097576      -14.40900     -51.317000\n",
       "2020-05-29   0.166667       29.72050     -51.479500\n",
       "2020-05-30   0.293636       33.55025     -94.267250\n",
       "2020-05-31   0.105500       -5.46250    -112.516500\n",
       "2020-06-01   0.183571       26.64000     -89.185250\n",
       "2020-06-02   0.106667        9.87950     -81.623500"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_by_date(df, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'str' and 'datetime.datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-908c7dc0437b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_by_date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-97-d092216d8f4c>\u001b[0m in \u001b[0;36mget_by_date\u001b[1;34m(self, df, lookback)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_by_date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlookback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mfirstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoday\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlookback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'created'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mfirstd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'created'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'created'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'likes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m   1227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1229\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m                 raise TypeError(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1091\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\ops.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'str' and 'datetime.datetime'"
     ]
    }
   ],
   "source": [
    "a.get_by_date(df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-220e18e00e2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'created'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdfc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(self, rule, how, axis, fill_method, closed, label, convention, kind, loffset, limit, base, on, level)\u001b[0m\n\u001b[0;32m   8447\u001b[0m             \u001b[0mbase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8448\u001b[0m             \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8449\u001b[1;33m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8450\u001b[0m         )\n\u001b[0;32m   8451\u001b[0m         return _maybe_process_deprecations(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\resample.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(obj, kind, **kwds)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \"\"\"\n\u001b[0;32m   1305\u001b[0m     \u001b[0mtg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeGrouper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_resampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\resample.py\u001b[0m in \u001b[0;36m_get_resampler\u001b[1;34m(self, obj, kind)\u001b[0m\n\u001b[0;32m   1441\u001b[0m             \u001b[1;34m\"Only valid with DatetimeIndex, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1442\u001b[0m             \u001b[1;34m\"TimedeltaIndex or PeriodIndex, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m             \u001b[1;34m\"but got an instance of %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1444\u001b[0m         )\n\u001b[0;32m   1445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'"
     ]
    }
   ],
   "source": [
    "dfc = df.copy()\n",
    "dfc = dfc.resample('D', on='created').mean()\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>0.094861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>0.094624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-23</td>\n",
       "      <td>0.071540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-24</td>\n",
       "      <td>0.044306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-25</td>\n",
       "      <td>0.159545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0.126188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>0.131134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sentiment\n",
       "created              \n",
       "2020-05-21   0.094861\n",
       "2020-05-22   0.094624\n",
       "2020-05-23   0.071540\n",
       "2020-05-24   0.044306\n",
       "2020-05-25   0.159545\n",
       "2020-05-26   0.126188\n",
       "2020-05-27   0.131134"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "      <th>created</th>\n",
       "      <th>likes</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Stories vibe, for more.\\nüå™Ô∏èüòà\\n\\n.\\n#quarantine...</td>\n",
       "      <td>vivilimasantana</td>\n",
       "      <td>EARTH!!</td>\n",
       "      <td>2020-05-21 23:28:22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Help us identify views on #COVID19. If you're ...</td>\n",
       "      <td>covidprisk</td>\n",
       "      <td>Central New York</td>\n",
       "      <td>2020-05-21 23:01:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Quote of the day\\n\\nPlease follow us on-\\nYout...</td>\n",
       "      <td>Learnado8</td>\n",
       "      <td>Dhaka, Bangladesh</td>\n",
       "      <td>2020-05-22 22:45:50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Bangladesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Coronavirus Chronicles... you have the power, ...</td>\n",
       "      <td>guayilandia</td>\n",
       "      <td>washington dc</td>\n",
       "      <td>2020-05-22 22:15:33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>How yall coming out of Quarentine cuz this how...</td>\n",
       "      <td>ApolloSadeek</td>\n",
       "      <td>los angeles, CA</td>\n",
       "      <td>2020-05-22 22:02:04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>look and smile\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n#in...</td>\n",
       "      <td>ingridcorrea03</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>2020-05-23 23:28:12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>The weather : __/\\/\\/\\/\\__\\n\\nMe : ? ? ? ?\\n#T...</td>\n",
       "      <td>heavenlySkyee</td>\n",
       "      <td>Montgomery, AL</td>\n",
       "      <td>2020-05-23 23:16:55</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Therapy session scene. Short film I Just Look ...</td>\n",
       "      <td>JeffersonStil</td>\n",
       "      <td>S√£o Paulo, Brasil</td>\n",
       "      <td>2020-05-24 23:43:04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>https://t.co/eXR0yu1D0T\\n\\nSLVDE - OFF BALANCE...</td>\n",
       "      <td>OnliShak</td>\n",
       "      <td>London, England</td>\n",
       "      <td>2020-05-24 23:25:23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Girl from the North Country - üé∂üé∏bobdylan &amp;amp;...</td>\n",
       "      <td>LeninR22</td>\n",
       "      <td>Quito, Ecuador</td>\n",
       "      <td>2020-05-24 23:23:10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Ecuador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Day 13: The Pursuit of Happiness. \\n\\n#canada ...</td>\n",
       "      <td>MeganNez</td>\n",
       "      <td>Toronto, Ontario, Canada üá®üá¶</td>\n",
       "      <td>2020-05-25 23:53:54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Watch @BlackoutsBox's broadcast: Happy #TowelD...</td>\n",
       "      <td>BlackoutsBox</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2020-05-25 23:51:32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>#satsangsatyaprem #ficaemcasa #stayhome #queda...</td>\n",
       "      <td>satyaprem</td>\n",
       "      <td>brazil</td>\n",
       "      <td>2020-05-25 23:40:12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Let my dogs GF in the house this evening.Mishk...</td>\n",
       "      <td>sheen_bean13</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>2020-05-26 23:47:59</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>It's 5'oclock somewhere ü§óü§£üòé #cheers \\nTea Brea...</td>\n",
       "      <td>multimomtam</td>\n",
       "      <td>Cerritos, CA</td>\n",
       "      <td>2020-05-26 23:29:44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513636</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>#coronavirus #quarentine #freestyle SIG SICK! ...</td>\n",
       "      <td>SilenceIsGod1</td>\n",
       "      <td>Philly</td>\n",
       "      <td>2020-05-27 23:48:38</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>There's a limit #quarentinethoughts #quarentin...</td>\n",
       "      <td>sean_t_kelly2</td>\n",
       "      <td>Lenexa, KS</td>\n",
       "      <td>2020-05-27 23:07:20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Well, this was certainly a \"look\" ü§≠\\n\\n#mustac...</td>\n",
       "      <td>DexMorningstar</td>\n",
       "      <td>Auckland - New Zealand</td>\n",
       "      <td>2020-05-27 22:37:01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>New Zealand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet             user  \\\n",
       "0   Stories vibe, for more.\\nüå™Ô∏èüòà\\n\\n.\\n#quarantine...  vivilimasantana   \n",
       "1   Help us identify views on #COVID19. If you're ...       covidprisk   \n",
       "2   Quote of the day\\n\\nPlease follow us on-\\nYout...        Learnado8   \n",
       "3   Coronavirus Chronicles... you have the power, ...      guayilandia   \n",
       "4   How yall coming out of Quarentine cuz this how...     ApolloSadeek   \n",
       "5   look and smile\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n#in...   ingridcorrea03   \n",
       "6   The weather : __/\\/\\/\\/\\__\\n\\nMe : ? ? ? ?\\n#T...    heavenlySkyee   \n",
       "7   Therapy session scene. Short film I Just Look ...    JeffersonStil   \n",
       "8   https://t.co/eXR0yu1D0T\\n\\nSLVDE - OFF BALANCE...         OnliShak   \n",
       "9   Girl from the North Country - üé∂üé∏bobdylan &amp;...         LeninR22   \n",
       "10  Day 13: The Pursuit of Happiness. \\n\\n#canada ...         MeganNez   \n",
       "11  Watch @BlackoutsBox's broadcast: Happy #TowelD...     BlackoutsBox   \n",
       "12  #satsangsatyaprem #ficaemcasa #stayhome #queda...        satyaprem   \n",
       "13  Let my dogs GF in the house this evening.Mishk...     sheen_bean13   \n",
       "14  It's 5'oclock somewhere ü§óü§£üòé #cheers \\nTea Brea...      multimomtam   \n",
       "15  #coronavirus #quarentine #freestyle SIG SICK! ...    SilenceIsGod1   \n",
       "16  There's a limit #quarentinethoughts #quarentin...    sean_t_kelly2   \n",
       "17  Well, this was certainly a \"look\" ü§≠\\n\\n#mustac...   DexMorningstar   \n",
       "\n",
       "                       location             created  likes  sentiment  \\\n",
       "0                       EARTH!! 2020-05-21 23:28:22      0   0.650000   \n",
       "1              Central New York 2020-05-21 23:01:00      1   0.000000   \n",
       "2             Dhaka, Bangladesh 2020-05-22 22:45:50      0   0.000000   \n",
       "3                 washington dc 2020-05-22 22:15:33      0   0.250000   \n",
       "4               los angeles, CA 2020-05-22 22:02:04      1   0.000000   \n",
       "5                        Brasil 2020-05-23 23:28:12      1   0.144444   \n",
       "6                Montgomery, AL 2020-05-23 23:16:55      0  -0.500000   \n",
       "7             S√£o Paulo, Brasil 2020-05-24 23:43:04      0   0.175000   \n",
       "8               London, England 2020-05-24 23:25:23      0   0.000000   \n",
       "9                Quito, Ecuador 2020-05-24 23:23:10      1   0.000000   \n",
       "10  Toronto, Ontario, Canada üá®üá¶ 2020-05-25 23:53:54      0   0.700000   \n",
       "11                 New York, NY 2020-05-25 23:51:32      1   0.800000   \n",
       "12                       brazil 2020-05-25 23:40:12      0   0.000000   \n",
       "13                  Nova Scotia 2020-05-26 23:47:59      1  -0.600000   \n",
       "14                 Cerritos, CA 2020-05-26 23:29:44      0   0.513636   \n",
       "15                       Philly 2020-05-27 23:48:38      0  -0.714286   \n",
       "16                   Lenexa, KS 2020-05-27 23:07:20      0   0.000000   \n",
       "17       Auckland - New Zealand 2020-05-27 22:37:01      0   0.214286   \n",
       "\n",
       "           country  \n",
       "0    United States  \n",
       "1    United States  \n",
       "2       Bangladesh  \n",
       "3    United States  \n",
       "4    United States  \n",
       "5           Brazil  \n",
       "6    United States  \n",
       "7           Brazil  \n",
       "8   United Kingdom  \n",
       "9          Ecuador  \n",
       "10          Canada  \n",
       "11   United States  \n",
       "12          Brazil  \n",
       "13          Canada  \n",
       "14   United States  \n",
       "15   United States  \n",
       "16   United States  \n",
       "17     New Zealand  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(datetime.now())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(datetime.now() - timedelta(days = 90))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    print(df.iloc[i]['Tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
